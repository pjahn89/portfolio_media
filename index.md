---
layout: page
title: Home
permalink: /
---

![index (hero)](/assets/img/index_banner.png)

# Long-horizon coherence in AI systems

I build models and interfaces that compress complex, shifting environments—games, markets, platforms, and narrative—into representations that remain useful over time.

My through-line is **coherence under drift**:  
what state matters, how it updates, and how humans can inspect and steer it.

---

## What I’m building

### 1) Compression for long-horizon dynamics
When systems evolve, surface metrics become unreliable. I focus on representations that remain stable enough to support prediction and decision-making over time.

### 2) Memory as state, not text
LLMs can be locally fluent while globally inconsistent. I’m interested in explicit state representations (facts, constraints, relationships) and update rules that prevent drift.

### 3) Interfaces for auditing and steering
A model only matters if a human can use it. I build artifacts—dashboards, diagrams, and “one-page” summaries—that turn learned structure into actionable decisions.

---

## Stories (extended project narratives)

> These are long-form case studies with receipts: **problem → mechanism → evidence → what changed**.


![Genji scouting output (hero)](/assets/img/2k_banner.png)

### Genji / NBA 2K League — scouting under team confounding and meta drift
Build a talent evaluation system when the only stable label is winning, but outcomes are entangled with team context and changing rules.  
[Read the story →](/stories/genji.md)

### Delfi Labs — control under uncertainty with real constraints
Adaptive decision policies when user behavior, constraints, and regimes change the “right” action over time.  
[Read the story →](/stories/delfi/)

![Twitch (hero)](/assets/img/twitch_banner.png)

### Clipping the Best Moments — Winnowing high-density high-volume video data from gaming livestreams with text techniques
In a pre-ChatGPT era, what techniques were possible to analyze hours upon hours of livestreaming content and identify the best moments for deeper analysis?   
[Read the story →](/stories/genji_twitchchat.md)


### Twitch / Mixer — emergent structure and power laws
Test whether “community” behaves like a transferable asset; measure where naive power-law intuition fails.  
[Read the story →](/stories/power-laws/)

### Narrative memory — explicit state for long-horizon coherence
Prevent story drift with state tracking (secrets, relationships, constraints) and explicit update rules.  
[Read the story →](/stories/narrative-memory/)

---

## Research direction (one paragraph)
I’m pursuing a unified view of narrative and mathematics as tools for compression: both are ways to represent complex systems with enough fidelity to remain predictive and meaningful over long time horizons. My work centers on identifying minimal state, designing update rules under uncertainty, and building interfaces that make coherence legible.
